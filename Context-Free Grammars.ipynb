{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context-Free Grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK makes it easy to generate a CFG by providing a helper function.\n",
    "\n",
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we created a CFG, which we can then feed into a parser object. \n",
    "\n",
    "parser = nltk.ChartParser(groucho_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a parser, we can use it to parse sentences by passing in a tokenized sentence to the parser's .parse() method. This will return 0 or more Parse Trees for that sentence. If the sentence cannot be parsed, it will return no trees. If there is more than one grammatically valid way (according to the rules defined in our CFG) to parse the sentence, then it will return them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing A Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sample grammar. The grammar can be broken down into two sections:\n",
    "\n",
    "Rules defining valid compositions for Sentences (S), Prepositional Phrases (PP), Noun Phrases (NP), and Verb Phrases (VP). These are incomplete, and we'll need to modify them to get the sentences to parse correctly\n",
    "\n",
    "Mappings that define the POS tag for each word we'll be working with, as seen from the line Det -> and all the lines after it. These will be provided for you at each step, so that you only have to worry about the rules\n",
    "\n",
    "- Step 2 defines the sentences we'll be working with as strings\n",
    "- Step 3 creates a tokenized version of each sentence\n",
    "- Step 4 creates a new parser with our grammar CFG\n",
    "- Step 5 tries to parse the tokenized version of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | \n",
    "VP -> V NP | VP PP\n",
    "Det -> 'the'\n",
    "Adj -> '100m'\n",
    "N -> 'usain_bolt' | 'record' | \n",
    "V -> 'broke'\n",
    "P -> \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "from nltk import word_tokenize\n",
    "sent = 'usain_bolt broke the 100m record'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "tokenized_sent = word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "parser = nltk.ChartParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5\n",
    "for tree in parser.parse(tokenized_sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above didn't print anything, which means that our parser was unable to parse tokenized_sent correctly. Although it recognizes all the words (it would throw an error if it came across an unrecognized word), it doesn't contain the rules necessary to correctly parse this sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Noun Phrases (NP) need to be able to consist of Det followed by a Noun Phrase NP.\n",
    "- Noun Phrases need to be able to consist of Adj followed by an N."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try reloading our grammar, and reparsing our sentence.\n",
    "\n",
    "- Modify and recreate our CFG using our updated rules\n",
    "- Recreate our parser with the updated rules\n",
    "- Try to parse tokenized_sent and see if we get any output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N PP | N | Det NP | Adj NP\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'the'\n",
    "Adj -> '100m'\n",
    "N -> 'usain_bolt' | 'record' | \n",
    "V -> 'broke'\n",
    "P -> \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.ChartParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP (V broke) (NP (Det the) (NP (Adj 100m) (NP (N record))))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (V broke)\n",
      "    (NP (Det the) (N ) (PP (P ) (NP (Adj 100m) (NP (N record)))))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP (V broke) (NP (N )))\n",
      "    (PP (P ) (NP (Det the) (NP (Adj 100m) (NP (N record)))))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP (V broke) (NP (N )))\n",
      "    (PP\n",
      "      (P )\n",
      "      (NP (Det the) (N ) (PP (P ) (NP (Adj 100m) (NP (N record))))))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP (VP (V broke) (NP (N ))) (PP (P ) (NP (N ))))\n",
      "    (PP (P ) (NP (Det the) (NP (Adj 100m) (NP (N record)))))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP (VP (V broke) (NP (N ))) (PP (P ) (NP (N ))))\n",
      "    (PP\n",
      "      (P )\n",
      "      (NP (Det the) (N ) (PP (P ) (NP (Adj 100m) (NP (N record))))))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP (V broke) (NP (Det the) (NP (N ))))\n",
      "    (PP (P ) (NP (Adj 100m) (NP (N record))))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP (V broke) (NP (Det the) (N ) (PP (P ) (NP (N )))))\n",
      "    (PP (P ) (NP (Adj 100m) (NP (N record))))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP (VP (V broke) (NP (N ))) (PP (P ) (NP (Det the) (NP (N )))))\n",
      "    (PP (P ) (NP (Adj 100m) (NP (N record))))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (V broke) (NP (N )))\n",
      "      (PP (P ) (NP (Det the) (N ) (PP (P ) (NP (N ))))))\n",
      "    (PP (P ) (NP (Adj 100m) (NP (N record))))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (VP (V broke) (NP (N ))) (PP (P ) (NP (N ))))\n",
      "      (PP (P ) (NP (Det the) (NP (N )))))\n",
      "    (PP (P ) (NP (Adj 100m) (NP (N record))))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (VP (V broke) (NP (N ))) (PP (P ) (NP (N ))))\n",
      "      (PP (P ) (NP (Det the) (N ) (PP (P ) (NP (N ))))))\n",
      "    (PP (P ) (NP (Adj 100m) (NP (N record))))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP (VP (V broke) (NP (Det the) (NP (N )))) (PP (P ) (NP (N ))))\n",
      "    (PP (P ) (NP (Adj 100m) (NP (N record))))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (V broke) (NP (Det the) (N ) (PP (P ) (NP (N )))))\n",
      "      (PP (P ) (NP (N ))))\n",
      "    (PP (P ) (NP (Adj 100m) (NP (N record))))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP (V broke) (NP (Det the) (NP (Adj 100m) (NP (N )))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V broke)\n",
      "      (NP (Det the) (N ) (PP (P ) (NP (Adj 100m) (NP (N ))))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (V broke) (NP (N )))\n",
      "      (PP (P ) (NP (Det the) (NP (Adj 100m) (NP (N ))))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (V broke) (NP (N )))\n",
      "      (PP\n",
      "        (P )\n",
      "        (NP (Det the) (N ) (PP (P ) (NP (Adj 100m) (NP (N )))))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (VP (V broke) (NP (N ))) (PP (P ) (NP (N ))))\n",
      "      (PP (P ) (NP (Det the) (NP (Adj 100m) (NP (N ))))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (VP (V broke) (NP (N ))) (PP (P ) (NP (N ))))\n",
      "      (PP\n",
      "        (P )\n",
      "        (NP (Det the) (N ) (PP (P ) (NP (Adj 100m) (NP (N )))))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (V broke) (NP (Det the) (NP (N ))))\n",
      "      (PP (P ) (NP (Adj 100m) (NP (N )))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (V broke) (NP (Det the) (N ) (PP (P ) (NP (N )))))\n",
      "      (PP (P ) (NP (Adj 100m) (NP (N )))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP\n",
      "        (VP (V broke) (NP (N )))\n",
      "        (PP (P ) (NP (Det the) (NP (N )))))\n",
      "      (PP (P ) (NP (Adj 100m) (NP (N )))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP\n",
      "        (VP (V broke) (NP (N )))\n",
      "        (PP (P ) (NP (Det the) (N ) (PP (P ) (NP (N ))))))\n",
      "      (PP (P ) (NP (Adj 100m) (NP (N )))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP\n",
      "        (VP (VP (V broke) (NP (N ))) (PP (P ) (NP (N ))))\n",
      "        (PP (P ) (NP (Det the) (NP (N )))))\n",
      "      (PP (P ) (NP (Adj 100m) (NP (N )))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP\n",
      "        (VP (VP (V broke) (NP (N ))) (PP (P ) (NP (N ))))\n",
      "        (PP (P ) (NP (Det the) (N ) (PP (P ) (NP (N ))))))\n",
      "      (PP (P ) (NP (Adj 100m) (NP (N )))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP\n",
      "        (VP (V broke) (NP (Det the) (NP (N ))))\n",
      "        (PP (P ) (NP (N ))))\n",
      "      (PP (P ) (NP (Adj 100m) (NP (N )))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP\n",
      "        (VP (V broke) (NP (Det the) (N ) (PP (P ) (NP (N )))))\n",
      "        (PP (P ) (NP (N ))))\n",
      "      (PP (P ) (NP (Adj 100m) (NP (N )))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (V broke) (NP (Det the) (NP (Adj 100m) (NP (N )))))\n",
      "      (PP (P ) (NP (N ))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP\n",
      "        (V broke)\n",
      "        (NP (Det the) (N ) (PP (P ) (NP (Adj 100m) (NP (N ))))))\n",
      "      (PP (P ) (NP (N ))))\n",
      "    (PP (P ) (NP (N record)))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP (V broke) (NP (Det the) (NP (Adj 100m) (NP (N record)))))\n",
      "    (PP (P ) (NP (N )))))\n",
      "(S\n",
      "  (NP (N usain_bolt))\n",
      "  (VP\n",
      "    (VP\n",
      "      (V broke)\n",
      "      (NP (Det the) (N ) (PP (P ) (NP (Adj 100m) (NP (N record))))))\n",
      "    (PP (P ) (NP (N )))))\n"
     ]
    }
   ],
   "source": [
    "for tree in parser.parse(tokenized_sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! But why are there so many trees? Because as our rules stand, there are multiple valid interpretations of the sentence. This is because we have some empty things like PP -> P NP that don't currently have rules, so they're triggering as false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've been manually labeling our words to construct our CFGs. However, this strategy obviously doesn't scale well to the real world -- it would take way too long to label every possible word with a part of speech, and generate every rule possible for a CFG. \n",
    "\n",
    "Luckily, the linguists and programmers have provided a quick and easy way to have this done for us, thanks to the Penn Tree Bank! The Penn Tree Bank is \"a large annotated corpus of English\", according to the researchers at Penn that created it. This means that it already has a ton of well-labeled examples for POS tagging. \n",
    "\n",
    "For us, this means that we can easily use NLTK to generate POS tags for our corpora, without having to worry about hand labeling or generating parse trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating POS tags is very simple with NLTK -- all we need to do is pass in a tokenized version of our corpus and NLTK will return a list of tuples containing the token and it's part of speech.\n",
    "\n",
    "Note that the abbreviations NLTK uses for their POS tags come from the Penn Tree Bank. To understand what these tags stand for, take a look at this reference: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('usain_bolt', 'JJ'),\n",
       " ('broke', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('100m', 'CD'),\n",
       " ('record', 'NN')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is all it takes to generate POS tags using NLTK.\n",
    "\n",
    "nltk.pos_tag(tokenized_sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
